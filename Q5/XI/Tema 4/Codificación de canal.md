[[Tema 4-Fundamentos de la codificaci√≥n de canal]]

## Transmisi√≥n de informaci√≥n
Una fuente transmite informaci√≥n (voz, audio, v√≠deo‚Ä¶) a trav√©s de un canal ruidoso (l√≠nea telef√≥nica, enlace √≥ptico, inal√°mbrico, medio de almacenamiento‚Ä¶). El objetivo es recuperar esa informaci√≥n con el menor n√∫mero de bits err√≥neos posible.

La codificaci√≥n de canal consiste en a√±adir redundancia para combatir los posibles errores. A√±adimos redundancia transmitiendo N bits por cada K bits. La tasa de codificaci√≥n es:
$$R=K/N$$
![[codificaci√≥n.png]]
El canal alterar√° algunos de los bits transmitidos de modo que el vector (palabra) de bits recibidos c' puede ser diferente al transmitido c.

## Canal sim√©trico binario
El Canal Sim√©trico Binario (Binary Symmetric Channel, BSC) con par√°metro p. Este canal tiene la propiedad de alterar el bit transmitido con una probabilidad p. Es "sim√©trico" porque la probabilidad de error es la misma para ambos bits posibles (0 y 1).

Env√≠a varias veces la informaci√≥n redundada. El bit que aparezca m√°s veces redundado es el que se elige. La decodificaci√≥n falla cuando el n√∫mero de errores es mayor que el n√∫mero de bits correctos.

## C√≥digo binario
Un c√≥digo binario es una colecci√≥n de elementos, donde cada elemento es una palabra c√≥digo. Cada palabra c√≥digo est√° formada por bits binarios (0 y 1). La longitud del c√≥digo, denotada como m, es el n√∫mero de bits en cada palabra c√≥digo. La cardinalidad del c√≥digo, denotada como N, es el n√∫mero total de palabras c√≥digo en el conjunto y se calcula como N=2^k. 

### Ejemplo: C√≥digo de 3-Repetici√≥n
Para un c√≥digo de 3-repetici√≥n, las palabras c√≥digo son {000, 111}.
- **Longitud del C√≥digo (m):** En este caso, m=3 ya que cada bit se repite tres veces.
- **Cardinalidad del C√≥digo (N):** Dado que hay dos palabras c√≥digo posibles (000 y 111), la cardinalidad es N=2.
- **Tasa de Codificaci√≥n (R):** En este caso, R=1/3‚Äã, ya que cada bit de la palabra fuente se representa con tres bits en la palabra c√≥digo.

### Distancia y errores
La distancia es la medida de la diferencia entre dos palabras c√≥digo.

La distancia de Hamming mide la diferencia entre dos palabras c√≥digo de igual longitud contando la cantidad de posiciones en las cuales los bits difieren. Por ejemplo, la distancia de Hamming entre "1101" y "1001" es 1, ya que difieren en un solo bit.

El peso de Hamming de una palabra c√≥digo es simplemente la cantidad de bits que tienen un valor diferente de cero. Es equivalente a la distancia de Hamming entre la palabra c√≥digo y un vector de ceros de la misma longitud. En otras palabras, es la cantidad de "unos" en la palabra c√≥digo.

La distancia m√≠nima de un c√≥digo es la distancia m√≠nima entre cualesquiera dos palabras c√≥digo.

Para decodificar dada una palabra recibida, escogemos como palabra transmitida aquella palabra c√≥digo m√°s pr√≥xima en distancia de Hamming.

Los errores que un c√≥digo puede detectar son:
$$t_{\text{detect}} = d_{\text{min}} - 1$$

Los errores que un c√≥digo puede corregir son:
$$t_{\text{correcci√≥n}} = \lfloor \frac{d_{\text{min}} - 1}{2} \rfloor$$


## C√≥digo lineal
Un c√≥digo binario se denomina "lineal" si es cerrado respecto a la suma de n-tuplas utilizando la operaci√≥n XOR (o suma m√≥dulo 2). Esto significa que la suma de cualquier par de palabras c√≥digo en el conjunto tambi√©n pertenece al conjunto.

Todo c√≥digo binario lineal incluye la palabra cero (la palabra c√≥digo que consiste en todos los bits igual a cero).

La distancia m√≠nima de un c√≥digo lineal es igual al peso m√≠nimo de las palabras no nulas.

El peso m√≠nimo de un c√≥digo es la menor cantidad de bits diferentes entre cualquier par de palabras c√≥digo diferentes.

La matriz generadora es una matriz que se utiliza para generar los c√≥digos en un c√≥digo lineal. Cualquier palabra de c√≥digo puede ser generada multiplicando un vector de informaci√≥n (la palabra original sin errores) por la matriz G.

Supongamos que $G$ es una matriz generadora de un c√≥digo lineal, y su representaci√≥n es $G = \left[ \begin{array}{c|c} I & P \end{array} \right]$. Entonces, si $\mathbf{v}$ es un vector de informaci√≥n, la palabra de c√≥digo $\mathbf{c}$ se obtiene como $\mathbf{c} = \mathbf{v} \cdot G$.

![[hamming 47.png]]
![[hamming 2.png]]
El c√≥digo dual C‚ä• consiste en todos los vectores que son ortogonales a todos los vectores en C. 

La matriz de control de paridad H de un c√≥digo C es una matriz que define las restricciones de paridad en el c√≥digo. Un vector v es una palabra de c√≥digo v√°lida si y solo si:
$$\mathbf{v} \cdot \mathbf{H}^T = 0$$

Se obtiene como: 
$$H = \begin{bmatrix}
1 & 1 & 1 & 0 & 1 & 0 & 0 \\
1 & 1 & 0 & 1 & 0 & 1 & 0 \\
1 & 0 & 1 & 1 & 0 & 0 & 1 \\
\end{bmatrix}
$$

H es P transpuesta y a su lado la identidad.

Un s√≠ndrome es la palabra c√≥digo recibida por H transpuesta. Si da 0 es una palabra c√≥digo.

### Descodificaci√≥n √≥ptima
Transmitimos ùëê, canal suma error ùëí, recibimos c‚Ä≤ = c + e.

Hay 2n‚àík posibles s√≠ndromes, ya que hay n‚àík bits de informaci√≥n en la palabra y cada uno puede tener un valor de 0 o 1. Hay 2^n posibles patrones de error, ya que cada uno de los ùëõn bits de la palabra recibida puede tener un error o no tenerlo.

 Para decodificar la palabra recibida:
 + Se calcula su s√≠ndrome s‚Ä≤.
- Se busca en el "standard array" el patr√≥n de error de peso m√≠nimo que corresponde al s√≠ndrome s‚Ä≤.
- La suma de este patr√≥n de error a la palabra recibida produce la palabra transmitida original, ya que c‚Ä≤+e=(c+e)+e=c.

La tabla est√°ndar se construye enumerando todos los posibles s√≠ndromes (vectores resultantes del producto c‚Ä≤HT) y asoci√°ndolos con los patrones de error correspondientes:
![[tabla.png]]

La regla de decodificaci√≥n es √≥ptima ya que la probabilidad de un patr√≥n de error es mayor que la de cualquier otro con mayor peso.

Si permitimos que el c√≥digo de Hamming sea NO sistem√°tico, el valor en decimal del s√≠ndrome nos indica la posici√≥n del bit en error.
![[hamming no sistematico.png]]
### Hamming extendido
C√≥digo de Hamming con un bit de paridad adicional que cubre todos los bits, con lo que consigue ùëëm√≠n = 4. Puede detectar si hubo exactamente 1 √≥ 2 errores. La capacidad de correcci√≥n sigue siendo 1 error. Por ejemplo:
![[hamming extendido.png]]